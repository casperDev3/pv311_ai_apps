# –ú–∞—à–∏–Ω–Ω–µ –Ω–∞–≤—á–∞–Ω–Ω—è: –î–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å, –í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å, –ì—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π –±—É—Å—Ç–∏–Ω–≥ —Ç–∞ –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è
# –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ –¥–ª—è –∑–∞–Ω—è—Ç—å

# %%
# –Ü–º–ø–æ—Ä—Ç –Ω–µ–æ–±—Ö—ñ–¥–Ω–∏—Ö –±—ñ–±–ª—ñ–æ—Ç–µ–∫
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import mean_squared_error, accuracy_score, classification_report, confusion_matrix
from sklearn.metrics import precision_score, recall_score, f1_score
import xgboost as xgb
from sklearn.datasets import load_boston, load_breast_cancer, load_iris
import warnings

warnings.filterwarnings('ignore')

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

print("‚úÖ –í—Å—ñ –±—ñ–±–ª—ñ–æ—Ç–µ–∫–∏ —É—Å–ø—ñ—à–Ω–æ —ñ–º–ø–æ—Ä—Ç–æ–≤–∞–Ω—ñ!")

# %%
# =============================================================================
# –ü–ê–†–ê 1: –î–ï–†–ï–í–ê –†–Ü–®–ï–ù–¨ –Ü –í–ò–ü–ê–î–ö–û–í–ò–ô –õ–Ü–°
# =============================================================================

# –ß–∞—Å—Ç–∏–Ω–∞ 1: –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –∫–æ–Ω—Ü–µ–ø—Ü—ñ—ó –µ–Ω—Ç—Ä–æ–ø—ñ—ó
print("üå≥ –î–ï–†–ï–í–ê –†–Ü–®–ï–ù–¨: –†–æ–∑—É–º—ñ–Ω–Ω—è –µ–Ω—Ç—Ä–æ–ø—ñ—ó")
print("=" * 50)


def calculate_entropy(y):
    """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –µ–Ω—Ç—Ä–æ–ø—ñ—ó –¥–ª—è –º–∞—Å–∏–≤—É –º—ñ—Ç–æ–∫"""
    _, counts = np.unique(y, return_counts=True)
    probabilities = counts / len(y)
    entropy = -np.sum(probabilities * np.log2(probabilities + 1e-10))
    return entropy


# –ü—Ä–∏–∫–ª–∞–¥ —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –µ–Ω—Ç—Ä–æ–ø—ñ—ó
example_labels = ['sunny', 'sunny', 'sunny', 'sunny', 'sunny', 'sunny', 'sunny', 'sunny', 'rainy', 'rainy']
entropy_value = calculate_entropy(example_labels)
print(f"–ü—Ä–∏–∫–ª–∞–¥: {example_labels}")
print(f"–ï–Ω—Ç—Ä–æ–ø—ñ—è = {entropy_value:.3f}")


# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –µ–Ω—Ç—Ä–æ–ø—ñ—ó
def plot_entropy():
    p = np.linspace(0.01, 0.99, 100)
    entropy = -p * np.log2(p) - (1 - p) * np.log2(1 - p)

    plt.figure(figsize=(8, 5))
    plt.plot(p, entropy, 'b-', linewidth=2)
    plt.xlabel('–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –∫–ª–∞—Å—É 1')
    plt.ylabel('–ï–Ω—Ç—Ä–æ–ø—ñ—è')
    plt.title('–§—É–Ω–∫—Ü—ñ—è –µ–Ω—Ç—Ä–æ–ø—ñ—ó –¥–ª—è –±—ñ–Ω–∞—Ä–Ω–æ—ó –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó')
    plt.grid(True, alpha=0.3)
    plt.axvline(x=0.5, color='r', linestyle='--', alpha=0.7, label='–ú–∞–∫—Å–∏–º—É–º –Ω–µ–≤–∏–∑–Ω–∞—á–µ–Ω–æ—Å—Ç—ñ')
    plt.legend()
    plt.show()


plot_entropy()

# %%
# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –ø—Ä–æ –Ω–µ—Ä—É—Ö–æ–º—ñ—Å—Ç—å (Housing prices)
print("\nüè† –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –î–ê–ù–ò–• –ü–†–û –ù–ï–†–£–•–û–ú–Ü–°–¢–¨")
print("=" * 40)

# –°—Ç–≤–æ—Ä–∏–º–æ —Å–∏–Ω—Ç–µ—Ç–∏—á–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç, —Å—Ö–æ–∂–∏–π –Ω–∞ Boston Housing
np.random.seed(42)
n_samples = 500

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –æ–∑–Ω–∞–∫
data = {
    'rooms': np.random.normal(6, 2, n_samples),  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –∫—ñ–º–Ω–∞—Ç
    'age': np.random.uniform(0, 100, n_samples),  # –í—ñ–∫ –±—É–¥–∏–Ω–∫—É
    'distance_to_center': np.random.exponential(5, n_samples),  # –í—ñ–¥—Å—Ç–∞–Ω—å –¥–æ —Ü–µ–Ω—Ç—Ä—É
    'crime_rate': np.random.exponential(0.5, n_samples),  # –†—ñ–≤–µ–Ω—å –∑–ª–æ—á–∏–Ω–Ω–æ—Å—Ç—ñ
    'pollution': np.random.normal(0.5, 0.2, n_samples),  # –†—ñ–≤–µ–Ω—å –∑–∞–±—Ä—É–¥–Ω–µ–Ω–Ω—è
}

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó (—Ü—ñ–Ω–∞) –Ω–∞ –æ—Å–Ω–æ–≤—ñ –æ–∑–Ω–∞–∫
price = (
        data['rooms'] * 15000 +  # –ë—ñ–ª—å—à–µ –∫—ñ–º–Ω–∞—Ç = –≤–∏—â–∞ —Ü—ñ–Ω–∞
        (100 - data['age']) * 500 +  # –ù–æ–≤—ñ—à—ñ –±—É–¥–∏–Ω–∫–∏ –¥–æ—Ä–æ–∂—á–µ
        -data['distance_to_center'] * 2000 +  # –ë–ª–∏–∂—á–µ –¥–æ —Ü–µ–Ω—Ç—Ä—É = –¥–æ—Ä–æ–∂—á–µ
        -data['crime_rate'] * 10000 +  # –ú–µ–Ω—à–µ –∑–ª–æ—á–∏–Ω–Ω–æ—Å—Ç—ñ = –¥–æ—Ä–æ–∂—á–µ
        -data['pollution'] * 20000 +  # –ú–µ–Ω—à–µ –∑–∞–±—Ä—É–¥–Ω–µ–Ω–Ω—è = –¥–æ—Ä–æ–∂—á–µ
        np.random.normal(0, 10000, n_samples)  # –í–∏–ø–∞–¥–∫–æ–≤–∏–π —à—É–º
)

data['price'] = np.maximum(price, 50000)  # –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∞ —Ü—ñ–Ω–∞ 50–∫

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è DataFrame
df = pd.DataFrame(data)

print("–ü–µ—Ä—à—ñ 5 —Ä—è–¥–∫—ñ–≤ –¥–∞—Ç–∞—Å–µ—Ç—É:")
print(df.head())
print(f"\n–†–æ–∑–º—ñ—Ä –¥–∞—Ç–∞—Å–µ—Ç—É: {df.shape}")
print(f"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
print(df.describe())

# %%
# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–∞–Ω–∏—Ö
print("\nüìä –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –î–ê–ù–ò–•")
print("=" * 25)

fig, axes = plt.subplots(2, 3, figsize=(15, 10))
axes = axes.flatten()

for i, column in enumerate(df.columns):
    if i < len(axes):
        if column == 'price':
            axes[i].hist(df[column], bins=30, alpha=0.7, color='red')
            axes[i].set_title(f'–†–æ–∑–ø–æ–¥—ñ–ª: {column} (–¶—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞)')
        else:
            axes[i].scatter(df[column], df['price'], alpha=0.6)
            axes[i].set_xlabel(column)
            axes[i].set_ylabel('price')
            axes[i].set_title(f'{column} vs price')

# –í–∏–¥–∞–ª–µ–Ω–Ω—è –∑–∞–π–≤–æ–≥–æ –≥—Ä–∞—Ñ—ñ–∫–∞
if len(df.columns) < len(axes):
    fig.delaxes(axes[-1])

plt.tight_layout()
plt.show()

# %%
# –†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å
print("\nüå≥ –î–ï–†–ï–í–û –†–Ü–®–ï–ù–¨ –î–õ–Ø –ü–†–û–ì–ù–û–ó–£–í–ê–ù–ù–Ø –¶–Ü–ù")
print("=" * 45)

# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö
X = df.drop('price', axis=1)
y = df['price']

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—É —Ç–∞ —Ç–µ—Å—Ç–æ–≤—É –≤–∏–±—ñ—Ä–∫–∏
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å
dt_regressor = DecisionTreeRegressor(
    max_depth=5,  # –û–±–º–µ–∂—É—î–º–æ –≥–ª–∏–±–∏–Ω—É –¥–ª—è –∑–∞–ø–æ–±—ñ–≥–∞–Ω–Ω—è –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—é
    min_samples_split=10,  # –ú—ñ–Ω—ñ–º—É–º –∑—Ä–∞–∑–∫—ñ–≤ –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
    min_samples_leaf=5,  # –ú—ñ–Ω—ñ–º—É–º –∑—Ä–∞–∑–∫—ñ–≤ –≤ –ª–∏—Å—Ç—ñ
    random_state=42
)

dt_regressor.fit(X_train, y_train)

# –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
y_pred_dt = dt_regressor.predict(X_test)

# –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ
mse_dt = mean_squared_error(y_test, y_pred_dt)
rmse_dt = np.sqrt(mse_dt)

print(f"–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å:")
print(f"RMSE: {rmse_dt:.2f}")
print(f"–°–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {np.mean(np.abs(y_test - y_pred_dt)):.2f}")

# –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
feature_importance_dt = pd.DataFrame({
    'feature': X.columns,
    'importance': dt_regressor.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\n–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ (–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å):")
print(feature_importance_dt)

# %%
# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å (—Å–ø—Ä–æ—â–µ–Ω–∞ –≤–µ—Ä—Å—ñ—è)
print("\nüé® –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –î–ï–†–ï–í–ê –†–Ü–®–ï–ù–¨")
print("=" * 35)

plt.figure(figsize=(20, 10))
plot_tree(dt_regressor,
          feature_names=X.columns,
          max_depth=3,  # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à—ñ 3 —Ä—ñ–≤–Ω—ñ
          filled=True,
          fontsize=10)
plt.title("–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å –¥–ª—è –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ü—ñ–Ω –Ω–∞ –Ω–µ—Ä—É—Ö–æ–º—ñ—Å—Ç—å")
plt.show()

# %%
# –í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å
print("\nüå≤ –í–ò–ü–ê–î–ö–û–í–ò–ô –õ–Ü–°")
print("=" * 20)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ –ª—ñ—Å—É
rf_regressor = RandomForestRegressor(
    n_estimators=100,  # –ö—ñ–ª—å–∫—ñ—Å—Ç—å –¥–µ—Ä–µ–≤
    max_depth=10,  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≥–ª–∏–±–∏–Ω–∞
    min_samples_split=5,  # –ú—ñ–Ω—ñ–º—É–º –∑—Ä–∞–∑–∫—ñ–≤ –¥–ª—è —Ä–æ–∑–¥—ñ–ª–µ–Ω–Ω—è
    min_samples_leaf=2,  # –ú—ñ–Ω—ñ–º—É–º –∑—Ä–∞–∑–∫—ñ–≤ –≤ –ª–∏—Å—Ç—ñ
    random_state=42,
    n_jobs=-1  # –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –≤—Å—ñ—Ö —è–¥–µ—Ä –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞
)

rf_regressor.fit(X_train, y_train)

# –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
y_pred_rf = rf_regressor.predict(X_test)

# –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ
mse_rf = mean_squared_error(y_test, y_pred_rf)
rmse_rf = np.sqrt(mse_rf)

print(f"–í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å:")
print(f"RMSE: {rmse_rf:.2f}")
print(f"–°–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {np.mean(np.abs(y_test - y_pred_rf)):.2f}")

# –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
feature_importance_rf = pd.DataFrame({
    'feature': X.columns,
    'importance': rf_regressor.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\n–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ (–í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å):")
print(feature_importance_rf)

# %%
# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –¥–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å —Ç–∞ –≤–∏–ø–∞–¥–∫–æ–≤–æ–≥–æ –ª—ñ—Å—É
print("\nüìä –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –î–ï–†–ï–í–ê –†–Ü–®–ï–ù–¨ –¢–ê –í–ò–ü–ê–î–ö–û–í–û–ì–û –õ–Ü–°–£")
print("=" * 55)

# –ì—Ä–∞—Ñ—ñ–∫ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤
fig, axes = plt.subplots(1, 2, figsize=(15, 6))

# –î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å
axes[0].scatter(y_test, y_pred_dt, alpha=0.6)
axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[0].set_xlabel('–°–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è')
axes[0].set_ylabel('–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è')
axes[0].set_title(f'–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å (RMSE: {rmse_dt:.0f})')

# –í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å
axes[1].scatter(y_test, y_pred_rf, alpha=0.6)
axes[1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
axes[1].set_xlabel('–°–ø—Ä–∞–≤–∂–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è')
axes[1].set_ylabel('–ü—Ä–æ–≥–Ω–æ–∑–æ–≤–∞–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è')
axes[1].set_title(f'–í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å (RMSE: {rmse_rf:.0f})')

plt.tight_layout()
plt.show()

# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫
plt.figure(figsize=(12, 6))
x = np.arange(len(X.columns))
width = 0.35

plt.bar(x - width / 2, feature_importance_dt['importance'], width, label='–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å', alpha=0.8)
plt.bar(x + width / 2, feature_importance_rf['importance'], width, label='–í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å', alpha=0.8)

plt.xlabel('–û–∑–Ω–∞–∫–∏')
plt.ylabel('–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å')
plt.title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –æ–∑–Ω–∞–∫')
plt.xticks(x, X.columns, rotation=45)
plt.legend()
plt.tight_layout()
plt.show()

# %%
# =============================================================================
# –ü–ê–†–ê 2: –ì–†–ê–î–Ü–Ñ–ù–¢–ù–ò–ô –ë–£–°–¢–ò–ù–ì –¢–ê –õ–û–ì–Ü–°–¢–ò–ß–ù–ê –†–ï–ì–†–ï–°–Ü–Ø
# =============================================================================

# –ì—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π –±—É—Å—Ç–∏–Ω–≥ –∑ XGBoost
print("\nüöÄ –ì–†–ê–î–Ü–Ñ–ù–¢–ù–ò–ô –ë–£–°–¢–ò–ù–ì (XGBoost)")
print("=" * 35)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è XGBoost
xgb_regressor = xgb.XGBRegressor(
    n_estimators=100,
    max_depth=6,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

xgb_regressor.fit(X_train, y_train)

# –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
y_pred_xgb = xgb_regressor.predict(X_test)

# –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ
mse_xgb = mean_squared_error(y_test, y_pred_xgb)
rmse_xgb = np.sqrt(mse_xgb)

print(f"XGBoost:")
print(f"RMSE: {rmse_xgb:.2f}")
print(f"–°–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {np.mean(np.abs(y_test - y_pred_xgb)):.2f}")

# –í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ –¥–ª—è XGBoost
feature_importance_xgb = pd.DataFrame({
    'feature': X.columns,
    'importance': xgb_regressor.feature_importances_
}).sort_values('importance', ascending=False)

print(f"\n–í–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫ (XGBoost):")
print(feature_importance_xgb)

# %%
# –§—ñ–Ω–∞–ª—å–Ω–µ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –≤—Å—ñ—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ —Ä–µ–≥—Ä–µ—Å—ñ—ó
print("\nüèÜ –§–Ü–ù–ê–õ–¨–ù–ï –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ê–õ–ì–û–†–ò–¢–ú–Ü–í –†–ï–ì–†–ï–°–Ü–á")
print("=" * 45)

results_regression = pd.DataFrame({
    '–ê–ª–≥–æ—Ä–∏—Ç–º': ['–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å', '–í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å', 'XGBoost'],
    'RMSE': [rmse_dt, rmse_rf, rmse_xgb],
    'MAE': [
        np.mean(np.abs(y_test - y_pred_dt)),
        np.mean(np.abs(y_test - y_pred_rf)),
        np.mean(np.abs(y_test - y_pred_xgb))
    ]
})

print(results_regression)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è
plt.figure(figsize=(10, 6))
plt.bar(results_regression['–ê–ª–≥–æ—Ä–∏—Ç–º'], results_regression['RMSE'], alpha=0.7)
plt.xlabel('–ê–ª–≥–æ—Ä–∏—Ç–º–∏')
plt.ylabel('RMSE')
plt.title('–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ —Ä–µ–≥—Ä–µ—Å—ñ—ó')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

# %%
# =============================================================================
# –õ–û–ì–Ü–°–¢–ò–ß–ù–ê –†–ï–ì–†–ï–°–Ü–Ø –¢–ê –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–Ø
# =============================================================================

print("\nüéØ –õ–û–ì–Ü–°–¢–ò–ß–ù–ê –†–ï–ì–†–ï–°–Ü–Ø: –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–Ø")
print("=" * 40)

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó (—Ä–∞–∫ –≥—Ä—É–¥–µ–π)
cancer_data = load_breast_cancer()
X_cancer = pd.DataFrame(cancer_data.data, columns=cancer_data.feature_names)
y_cancer = cancer_data.target

print("–î–∞—Ç–∞—Å–µ—Ç –ø—Ä–æ —Ä–∞–∫ –≥—Ä—É–¥–µ–π:")
print(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –∑—Ä–∞–∑–∫—ñ–≤: {X_cancer.shape[0]}")
print(f"–ö—ñ–ª—å–∫—ñ—Å—Ç—å –æ–∑–Ω–∞–∫: {X_cancer.shape[1]}")
print(f"–ö–ª–∞—Å–∏: {cancer_data.target_names}")
print(f"–†–æ–∑–ø–æ–¥—ñ–ª –∫–ª–∞—Å—ñ–≤: {np.bincount(y_cancer)}")

# %%
# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è —Å–∏–≥–º–æ—ó–¥–Ω–æ—ó —Ñ—É–Ω–∫—Ü—ñ—ó
print("\nüìà –°–ò–ì–ú–û–á–î–ù–ê –§–£–ù–ö–¶–Ü–Ø")
print("=" * 22)


def sigmoid(z):
    """–°–∏–≥–º–æ—ó–¥–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è"""
    return 1 / (1 + np.exp(-z))


# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Å–∏–≥–º–æ—ó–¥–∏
z = np.linspace(-10, 10, 100)
y_sigmoid = sigmoid(z)

plt.figure(figsize=(10, 6))
plt.plot(z, y_sigmoid, 'b-', linewidth=3, label='œÉ(z) = 1/(1+e^(-z))')
plt.axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='–ü–æ—Ä—ñ–≥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó')
plt.axvline(x=0, color='gray', linestyle='--', alpha=0.5)
plt.xlabel('z (–ª—ñ–Ω—ñ–π–Ω–∞ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ—è –æ–∑–Ω–∞–∫)')
plt.ylabel('œÉ(z) (–π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å)')
plt.title('–°–∏–≥–º–æ—ó–¥–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è')
plt.grid(True, alpha=0.3)
plt.legend()
plt.ylim(-0.1, 1.1)
plt.show()

print("–ö–ª—é—á–æ–≤—ñ —Ç–æ—á–∫–∏ —Å–∏–≥–º–æ—ó–¥–∏:")
print(f"œÉ(-‚àû) ‚âà {sigmoid(-100):.6f}")
print(f"œÉ(0) = {sigmoid(0):.6f}")
print(f"œÉ(+‚àû) ‚âà {sigmoid(100):.6f}")

# %%
# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó
print("\nüîß –ü–Ü–î–ì–û–¢–û–í–ö–ê –î–ê–ù–ò–• –î–õ–Ø –õ–û–ì–Ü–°–¢–ò–ß–ù–û–á –†–ï–ì–†–ï–°–Ü–á")
print("=" * 48)

# –î–ª—è —Å–ø—Ä–æ—â–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ 2 –Ω–∞–π–≤–∞–∂–ª–∏–≤—ñ—à—ñ –æ–∑–Ω–∞–∫–∏
from sklearn.feature_selection import SelectKBest, f_classif

# –í–∏–±–∏—Ä–∞—î–º–æ 2 –Ω–∞–π–∫—Ä–∞—â—ñ –æ–∑–Ω–∞–∫–∏
selector = SelectKBest(score_func=f_classif, k=2)
X_cancer_selected = selector.fit_transform(X_cancer, y_cancer)

# –û—Ç—Ä–∏–º—É—î–º–æ –Ω–∞–∑–≤–∏ –≤–∏–±—Ä–∞–Ω–∏—Ö –æ–∑–Ω–∞–∫
selected_features = X_cancer.columns[selector.get_support()].tolist()
print(f"–í–∏–±—Ä–∞–Ω—ñ –æ–∑–Ω–∞–∫–∏ –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó: {selected_features}")

# –†–æ–∑–¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω—É —Ç–∞ —Ç–µ—Å—Ç–æ–≤—É –≤–∏–±—ñ—Ä–∫–∏
X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(
    X_cancer_selected, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer
)

# –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ (–≤–∞–∂–ª–∏–≤–æ –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó!)
scaler = StandardScaler()
X_train_cancer_scaled = scaler.fit_transform(X_train_cancer)
X_test_cancer_scaled = scaler.transform(X_test_cancer)

print(f"–§–æ—Ä–º–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö: {X_train_cancer_scaled.shape}")
print(f"–§–æ—Ä–º–∞ —Ç–µ—Å—Ç–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö: {X_test_cancer_scaled.shape}")

# %%
# –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è
print("\nüéØ –õ–û–ì–Ü–°–¢–ò–ß–ù–ê –†–ï–ì–†–ï–°–Ü–Ø")
print("=" * 25)

# –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞ –Ω–∞–≤—á–∞–Ω–Ω—è –º–æ–¥–µ–ª—ñ
logistic_model = LogisticRegression(random_state=42)
logistic_model.fit(X_train_cancer_scaled, y_train_cancer)

# –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
y_pred_cancer = logistic_model.predict(X_test_cancer_scaled)
y_pred_proba_cancer = logistic_model.predict_proba(X_test_cancer_scaled)[:, 1]

# –û—Å–Ω–æ–≤–Ω—ñ –º–µ—Ç—Ä–∏–∫–∏
accuracy = accuracy_score(y_test_cancer, y_pred_cancer)
precision = precision_score(y_test_cancer, y_pred_cancer)
recall = recall_score(y_test_cancer, y_pred_cancer)
f1 = f1_score(y_test_cancer, y_pred_cancer)

print(f"–†–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó:")
print(f"–¢–æ—á–Ω—ñ—Å—Ç—å (Accuracy): {accuracy:.3f}")
print(f"–ü—Ä–µ—Ü–∏–∑—ñ–π–Ω—ñ—Å—Ç—å (Precision): {precision:.3f}")
print(f"–ü–æ–≤–Ω–æ—Ç–∞ (Recall): {recall:.3f}")
print(f"F1-–º–µ—Ä–∞: {f1:.3f}")

print(f"\n–ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç–∏ –º–æ–¥–µ–ª—ñ:")
for i, coef in enumerate(logistic_model.coef_[0]):
    print(f"{selected_features[i]}: {coef:.4f}")
print(f"–í—ñ–ª—å–Ω–∏–π —á–ª–µ–Ω: {logistic_model.intercept_[0]:.4f}")

# %%
# Confusion Matrix
print("\nüìä –ú–ê–¢–†–ò–¶–Ø –ù–ï–í–Ü–î–ü–û–í–Ü–î–ù–û–°–¢–ï–ô (CONFUSION MATRIX)")
print("=" * 50)

# –û–±—á–∏—Å–ª–µ–Ω–Ω—è –º–∞—Ç—Ä–∏—Ü—ñ –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π
cm = confusion_matrix(y_test_cancer, y_pred_cancer)

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –º–∞—Ç—Ä–∏—Ü—ñ –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['–ó–ª–æ—è–∫—ñ—Å–Ω–∏–π', '–î–æ–±—Ä–æ—è–∫—ñ—Å–Ω–∏–π'],
            yticklabels=['–ó–ª–æ—è–∫—ñ—Å–Ω–∏–π', '–î–æ–±—Ä–æ—è–∫—ñ—Å–Ω–∏–π'])
plt.xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ –º—ñ—Ç–∫–∏')
plt.ylabel('–°–ø—Ä–∞–≤–∂–Ω—ñ –º—ñ—Ç–∫–∏')
plt.title('–ú–∞—Ç—Ä–∏—Ü—è –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π')
plt.show()

# –î–µ—Ç–∞–ª—å–Ω–∏–π —Ä–æ–∑–±—ñ—Ä –º–∞—Ç—Ä–∏—Ü—ñ
tn, fp, fn, tp = cm.ravel()
print("–î–µ—Ç–∞–ª—å–Ω–∏–π —Ä–æ–∑–±—ñ—Ä –º–∞—Ç—Ä–∏—Ü—ñ –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç–µ–π:")
print(f"True Negatives (TN): {tn} - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ –∑–ª–æ—è–∫—ñ—Å–Ω—ñ")
print(f"False Positives (FP): {fp} - –ø–æ–º–∏–ª–∫–æ–≤–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ —è–∫ –¥–æ–±—Ä–æ—è–∫—ñ—Å–Ω—ñ")
print(f"False Negatives (FN): {fn} - –ø–æ–º–∏–ª–∫–æ–≤–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ —è–∫ –∑–ª–æ—è–∫—ñ—Å–Ω—ñ")
print(f"True Positives (TP): {tp} - –ø—Ä–∞–≤–∏–ª—å–Ω–æ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω—ñ –¥–æ–±—Ä–æ—è–∫—ñ—Å–Ω—ñ")

print(f"\n–ó–Ω–∞—á–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫:")
print(f"Precision = TP/(TP+FP) = {tp}/({tp}+{fp}) = {precision:.3f}")
print(f"Recall = TP/(TP+FN) = {tp}/({tp}+{fn}) = {recall:.3f}")
print(f"F1-Score = 2*(Precision*Recall)/(Precision+Recall) = {f1:.3f}")

# %%
# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è Cross-Entropy Loss
print("\nüí∞ –§–£–ù–ö–¶–Ü–Ø –í–¢–†–ê–¢: CROSS-ENTROPY")
print("=" * 35)


def cross_entropy_loss(y_true, y_pred_proba):
    """–û–±—á–∏—Å–ª–µ–Ω–Ω—è cross-entropy loss"""
    # –î–æ–¥–∞—î–º–æ –º–∞–ª–µ–Ω—å–∫–µ —á–∏—Å–ª–æ –¥–ª—è —É–Ω–∏–∫–Ω–µ–Ω–Ω—è log(0)
    epsilon = 1e-15
    y_pred_proba = np.clip(y_pred_proba, epsilon, 1 - epsilon)

    return -np.mean(y_true * np.log(y_pred_proba) + (1 - y_true) * np.log(1 - y_pred_proba))


# –û–±—á–∏—Å–ª–µ–Ω–Ω—è loss –¥–ª—è –Ω–∞—à–∏—Ö –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤
loss = cross_entropy_loss(y_test_cancer, y_pred_proba_cancer)
print(f"Cross-entropy loss: {loss:.4f}")

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ñ—É–Ω–∫—Ü—ñ—ó –≤—Ç—Ä–∞—Ç
p_range = np.linspace(0.01, 0.99, 100)
loss_y1 = -np.log(p_range)  # –ö–æ–ª–∏ —Å–ø—Ä–∞–≤–∂–Ω—è –º—ñ—Ç–∫–∞ = 1
loss_y0 = -np.log(1 - p_range)  # –ö–æ–ª–∏ —Å–ø—Ä–∞–≤–∂–Ω—è –º—ñ—Ç–∫–∞ = 0

plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(p_range, loss_y1, 'b-', linewidth=2, label='y=1 (–¥–æ–±—Ä–æ—è–∫—ñ—Å–Ω–∏–π)')
plt.plot(p_range, loss_y0, 'r-', linewidth=2, label='y=0 (–∑–ª–æ—è–∫—ñ—Å–Ω–∏–π)')
plt.xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å')
plt.ylabel('Cross-entropy loss')
plt.title('–§—É–Ω–∫—Ü—ñ—è –≤—Ç—Ä–∞—Ç Cross-entropy')
plt.legend()
plt.grid(True, alpha=0.3)

plt.subplot(1, 2, 2)
plt.hist(y_pred_proba_cancer[y_test_cancer == 0], bins=20, alpha=0.7, label='–ó–ª–æ—è–∫—ñ—Å–Ω—ñ', color='red')
plt.hist(y_pred_proba_cancer[y_test_cancer == 1], bins=20, alpha=0.7, label='–î–æ–±—Ä–æ—è–∫—ñ—Å–Ω—ñ', color='blue')
plt.xlabel('–ü–µ—Ä–µ–¥–±–∞—á–µ–Ω–∞ –π–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å')
plt.ylabel('–ß–∞—Å—Ç–æ—Ç–∞')
plt.title('–†–æ–∑–ø–æ–¥—ñ–ª –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏—Ö –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç–µ–π')
plt.legend()
plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.7, label='–ü–æ—Ä—ñ–≥')

plt.tight_layout()
plt.show()

# %%
# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≥—Ä–∞–Ω–∏—Ü—ñ –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å
print("\nüé® –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –ì–†–ê–ù–ò–¶–Ü –ü–†–ò–ô–ù–Ø–¢–¢–Ø –†–Ü–®–ï–ù–¨")
print("=" * 45)


def plot_decision_boundary(X, y, model, scaler, title):
    """–í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≥—Ä–∞–Ω–∏—Ü—ñ –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å"""
    plt.figure(figsize=(10, 8))

    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—ñ—Ç–∫–∏ —Ç–æ—á–æ–∫
    h = 0.01
    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1
    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1
    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                         np.arange(y_min, y_max, h))

    # –ü—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è –¥–ª—è –≤—Å—ñ—î—ó —Å—ñ—Ç–∫–∏
    mesh_points = np.c_[xx.ravel(), yy.ravel()]
    mesh_points_scaled = scaler.transform(mesh_points)
    Z = model.predict_proba(mesh_points_scaled)[:, 1]
    Z = Z.reshape(xx.shape)

    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è
    plt.contourf(xx, yy, Z, levels=50, alpha=0.6, cmap='RdYlBu')
    plt.colorbar(label='–ô–º–æ–≤—ñ—Ä–Ω—ñ—Å—Ç—å –¥–æ–±—Ä–æ—è–∫—ñ—Å–Ω–æ—Å—Ç—ñ')

    # –ù–∞–Ω–µ—Å–µ–Ω–Ω—è —Ç–æ—á–æ–∫
    scatter = plt.scatter(X[:, 0], X[:, 1], c=y, cmap='RdYlBu', edgecolors='black')
    plt.xlabel(selected_features[0])
    plt.ylabel(selected_features[1])
    plt.title(title)

    # –î–æ–¥–∞–≤–∞–Ω–Ω—è –ª–µ–≥–µ–Ω–¥–∏
    handles, labels = scatter.legend_elements()
    plt.legend(handles, ['–ó–ª–æ—è–∫—ñ—Å–Ω–∏–π', '–î–æ–±—Ä–æ—è–∫—ñ—Å–Ω–∏–π'])

    plt.show()


plot_decision_boundary(X_train_cancer_scaled, y_train_cancer, logistic_model, scaler,
                       '–õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è: –ì—Ä–∞–Ω–∏—Ü—è –ø—Ä–∏–π–Ω—è—Ç—Ç—è —Ä—ñ—à–µ–Ω—å')

# %%
# –ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è —Ä—ñ–∑–Ω–∏—Ö –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
print("\nüèÜ –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ê–õ–ì–û–†–ò–¢–ú–Ü–í –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–á")
print("=" * 40)

# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ–≤–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç—É (–≤—Å—ñ –æ–∑–Ω–∞–∫–∏)
X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(
    X_cancer, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer
)

# –ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó
scaler_full = StandardScaler()
X_train_full_scaled = scaler_full.fit_transform(X_train_full)
X_test_full_scaled = scaler_full.transform(X_test_full)

# –°–ª–æ–≤–Ω–∏–∫ –∑ –∞–ª–≥–æ—Ä–∏—Ç–º–∞–º–∏
classifiers = {
    '–õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è': LogisticRegression(random_state=42),
    '–î–µ—Ä–µ–≤–æ —Ä—ñ—à–µ–Ω—å': DecisionTreeClassifier(max_depth=5, random_state=42),
    '–í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å': RandomForestClassifier(n_estimators=100, random_state=42),
    'XGBoost': xgb.XGBClassifier(random_state=42)
}

# –†–µ–∑—É–ª—å—Ç–∞—Ç–∏
results_classification = []

for name, classifier in classifiers.items():
    # –í–∏–±—ñ—Ä –¥–∞–Ω–∏—Ö (–º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω—ñ –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó, –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—ñ –¥–ª—è —ñ–Ω—à–∏—Ö)
    if name == '–õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è':
        X_train_used = X_train_full_scaled
        X_test_used = X_test_full_scaled
    else:
        X_train_used = X_train_full
        X_test_used = X_test_full

    # –ù–∞–≤—á–∞–Ω–Ω—è —Ç–∞ –ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è
    classifier.fit(X_train_used, y_train_full)
    y_pred = classifier.predict(X_test_used)

    # –ú–µ—Ç—Ä–∏–∫–∏
    accuracy = accuracy_score(y_test_full, y_pred)
    precision = precision_score(y_test_full, y_pred)
    recall = recall_score(y_test_full, y_pred)
    f1 = f1_score(y_test_full, y_pred)

    results_classification.append({
        '–ê–ª–≥–æ—Ä–∏—Ç–º': name,
        'Accuracy': accuracy,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1
    })

# –ü–µ—Ä–µ—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤ DataFrame
results_df = pd.DataFrame(results_classification)
print(results_df.round(3))

# %%
# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –∞–ª–≥–æ—Ä–∏—Ç–º—ñ–≤
print("\nüìä –í–Ü–ó–£–ê–õ–Ü–ó–ê–¶–Ü–Ø –ü–û–†–Ü–í–ù–Ø–ù–ù–Ø –ê–õ–ì–û–†–ò–¢–ú–Ü–í")
print("=" * 40)

# –ì—Ä–∞—Ñ—ñ–∫ –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–µ—Ç—Ä–∏–∫
fig, axes = plt.subplots(2, 2, figsize=(15, 12))
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']

for i, metric in enumerate(metrics):
    row, col = i // 2, i % 2
    bars = axes[row, col].bar(results_df['–ê–ª–≥–æ—Ä–∏—Ç–º'], results_df[metric], alpha=0.8)
    axes[row, col].set_title(f'{metric}')
    axes[row, col].set_ylabel('–ó–Ω–∞—á–µ–Ω–Ω—è')
    axes[row, col].set_ylim(0, 1)
    axes[row, col].tick_params(axis='x', rotation=45)

    # –î–æ–¥–∞–≤–∞–Ω–Ω—è –∑–Ω–∞—á–µ–Ω—å –Ω–∞ —Å—Ç–æ–≤–ø—á–∏–∫–∏
    for bar, value in zip(bars, results_df[metric]):
        height = bar.get_height()
        axes[row, col].text(bar.get_x() + bar.get_width() / 2., height + 0.01,
                            f'{value:.3f}', ha='center', va='bottom')

plt.tight_layout()
plt.show()

# %%
# –î–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç –ø–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è –Ω–∞–π–∫—Ä–∞—â–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º—É
print("\nüìã –î–ï–¢–ê–õ–¨–ù–ò–ô –ó–í–Ü–¢ –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–á")
print("=" * 35)

# –ó–Ω–∞—Ö–æ–¥–∏–º–æ –Ω–∞–π–∫—Ä–∞—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ F1-Score
best_algorithm = results_df.loc[results_df['F1-Score'].idxmax(), '–ê–ª–≥–æ—Ä–∏—Ç–º']
print(f"–ù–∞–π–∫—Ä–∞—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ F1-Score: {best_algorithm}")

# –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞ –Ω–∞–≤—á–∞—î–º–æ –Ω–∞–π–∫—Ä–∞—â—É –º–æ–¥–µ–ª—å
best_classifier = classifiers[best_algorithm]
if best_algorithm == '–õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è':
    best_classifier.fit(X_train_full_scaled, y_train_full)
    y_pred_best = best_classifier.predict(X_test_full_scaled)
else:
    best_classifier.fit(X_train_full, y_train_full)
    y_pred_best = best_classifier.predict(X_test_full)

# –î–µ—Ç–∞–ª—å–Ω–∏–π –∑–≤—ñ—Ç
print(f"\n–ó–≤—ñ—Ç –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –¥–ª—è {best_algorithm}:")
print(classification_report(y_test_full, y_pred_best,
                            target_names=['–ó–ª–æ—è–∫—ñ—Å–Ω–∏–π', '–î–æ–±—Ä–æ—è–∫—ñ—Å–Ω–∏–π']))

# %%
# –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—è –≤–∞–∂–ª–∏–≤–æ—Å—Ç—ñ –≤–∏–±–æ—Ä—É –ø–æ—Ä–æ–≥—É –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
print("\n‚öñÔ∏è –í–ü–õ–ò–í –ü–û–†–û–ì–£ –ö–õ–ê–°–ò–§–Ü–ö–ê–¶–Ü–á –ù–ê –ú–ï–¢–†–ò–ö–ò")
print("=" * 45)

# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ª–æ–≥—ñ—Å—Ç–∏—á–Ω—É —Ä–µ–≥—Ä–µ—Å—ñ—é –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó
log_reg = LogisticRegression(random_state=42)
log_reg.fit(X_train_full_scaled, y_train_full)
y_proba = log_reg.predict_proba(X_test_full_scaled)[:, 1]

# –†—ñ–∑–Ω—ñ –ø–æ—Ä–æ–≥–∏
thresholds = np.arange(0.1, 0.9, 0.1)
threshold_results = []

for threshold in thresholds:
    y_pred_threshold = (y_proba >= threshold).astype(int)

    precision = precision_score(y_test_full, y_pred_threshold)
    recall = recall_score(y_test_full, y_pred_threshold)
    f1 = f1_score(y_test_full, y_pred_threshold)

    threshold_results.append({
        '–ü–æ—Ä—ñ–≥': threshold,
        'Precision': precision,
        'Recall': recall,
        'F1-Score': f1
    })

threshold_df = pd.DataFrame(threshold_results)
print(threshold_df.round(3))

# –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≤–ø–ª–∏–≤—É –ø–æ—Ä–æ–≥—É
plt.figure(figsize=(12, 8))
plt.plot(threshold_df['–ü–æ—Ä—ñ–≥'], threshold_df['Precision'], 'o-', label='Precision', linewidth=2)
plt.plot(threshold_df['–ü–æ—Ä—ñ–≥'], threshold_df['Recall'], 's-', label='Recall', linewidth=2)
plt.plot(threshold_df['–ü–æ—Ä—ñ–≥'], threshold_df['F1-Score'], '^-', label='F1-Score', linewidth=2)
plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7, label='–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∏–π –ø–æ—Ä—ñ–≥ (0.5)')
plt.xlabel('–ü–æ—Ä—ñ–≥ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó')
plt.ylabel('–ó–Ω–∞—á–µ–Ω–Ω—è –º–µ—Ç—Ä–∏–∫–∏')
plt.title('–í–ø–ª–∏–≤ –ø–æ—Ä–æ–≥—É –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –Ω–∞ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª—ñ')
plt.legend()
plt.grid(True, alpha=0.3)
plt.show()

# %%
# –ü—ñ–¥—Å—É–º–æ–∫ —Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
print("\nüéì –ü–Ü–î–°–£–ú–û–ö –ó–ê–ù–Ø–¢–¢–Ø")
print("=" * 22)

print("üìö –©–æ –º–∏ –≤–∏–≤—á–∏–ª–∏:")
print("1. –î–µ—Ä–µ–≤–∞ —Ä—ñ—à–µ–Ω—å - –ø—Ä–æ—Å—Ç—ñ –¥–ª—è —ñ–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü—ñ—ó, –∞–ª–µ —Å—Ö–∏–ª—å–Ω—ñ –¥–æ –ø–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è")
print("2. –í–∏–ø–∞–¥–∫–æ–≤–∏–π –ª—ñ—Å - –ø–æ–∫—Ä–∞—â—É—î –¥–µ—Ä–µ–≤–∞ —á–µ—Ä–µ–∑ –∞–Ω—Å–∞–º–±–ª—é–≤–∞–Ω–Ω—è")
print("3. –ì—Ä–∞–¥—ñ—î–Ω—Ç–Ω–∏–π –±—É—Å—Ç–∏–Ω–≥ (XGBoost) - –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–µ –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è –ø–æ–º–∏–ª–æ–∫")
print("4. –õ–æ–≥—ñ—Å—Ç–∏—á–Ω–∞ —Ä–µ–≥—Ä–µ—Å—ñ—è - –ª—ñ–Ω–µ–π–Ω–∏–π –º–µ—Ç–æ–¥ –¥–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó –∑ –π–º–æ–≤—ñ—Ä–Ω–æ—Å—Ç—è–º–∏")
print("5. –ú–µ—Ç—Ä–∏–∫–∏ —è–∫–æ—Å—Ç—ñ: Precision, Recall, F1-Score, Confusion Matrix")

print("\nüîç –ö–ª—é—á–æ–≤—ñ –≤–∏—Å–Ω–æ–≤–∫–∏:")
print("‚Ä¢ –î–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó (–ø—Ä–æ–≥–Ω–æ–∑—É–≤–∞–Ω–Ω—è —Ü—ñ–Ω):")
print(f"  - –ù–∞–π–∫—Ä–∞—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º: XGBoost (RMSE: {rmse_xgb:.0f})")
print("‚Ä¢ –î–ª—è –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó (–¥—ñ–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ä–∞–∫—É):")
print(f"  - –ù–∞–π–∫—Ä–∞—â–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º: {best_algorithm}")

print("\nüí° –ü—Ä–∞–∫—Ç–∏—á–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó:")
print("‚Ä¢ –ó–∞–≤–∂–¥–∏ –º–∞—Å—à—Ç–∞–±—É–π—Ç–µ –¥–∞–Ω—ñ –¥–ª—è –ª–æ–≥—ñ—Å—Ç–∏—á–Ω–æ—ó —Ä–µ–≥—Ä–µ—Å—ñ—ó")
print("‚Ä¢ –î–ª—è –º–µ–¥–∏—á–Ω–∏—Ö –∑–∞–¥–∞—á –≤–∏—Å–æ–∫–∏–π Recall —á–∞—Å—Ç–æ –≤–∞–∂–ª–∏–≤—ñ—à–∏–π –∑–∞ Precision")
print("‚Ä¢ –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –∫—Ä–æ—Å-–≤–∞–ª—ñ–¥–∞—Ü—ñ—é –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ —Å—Ç–∞–±—ñ–ª—å–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ")
print("‚Ä¢ –ï–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π—Ç–µ –∑ —Ä—ñ–∑–Ω–∏–º–∏ –ø–æ—Ä–æ–≥–∞–º–∏ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—ó")

print("\nüè† –î–æ–º–∞—à–Ω—î –∑–∞–≤–¥–∞–Ω–Ω—è:")
print("1. –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –≤–ª–∞—Å–Ω–∏–π –¥–∞—Ç–∞—Å–µ—Ç")
print("2. –ó–∞—Å—Ç–æ—Å—É–π—Ç–µ –≤—Å—ñ –≤–∏–≤—á–µ–Ω—ñ –∞–ª–≥–æ—Ä–∏—Ç–º–∏")
print("3. –ü–æ—Ä—ñ–≤–Ω—è–π—Ç–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —Ç–∞ –∑—Ä–æ–±—ñ—Ç—å –≤–∏—Å–Ω–æ–≤–∫–∏")
print("4. –ü–æ–µ–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç—É–π—Ç–µ –∑ –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")

print("\n‚úÖ –ó–∞–Ω—è—Ç—Ç—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –£—Å–ø—ñ—Ö—ñ–≤ —É –≤–∏–≤—á–µ–Ω–Ω—ñ –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è! üöÄ")